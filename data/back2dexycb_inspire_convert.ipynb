{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "865404e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_names = ['WRJTx', 'WRJTy', 'WRJTz']\n",
    "rot_names = ['WRJRx', 'WRJRy', 'WRJRz']\n",
    "joint_names = [\n",
    "    \"R_thumb_MCP_joint1\",\n",
    "    \"R_thumb_MCP_joint2\",\n",
    "    \"R_thumb_PIP_joint\",\n",
    "    \"R_thumb_DIP_joint\",\n",
    "    \"R_index_MCP_joint\",\n",
    "    \"R_index_DIP_joint\",\n",
    "    \"R_middle_MCP_joint\",\n",
    "    \"R_middle_DIP_joint\",\n",
    "    \"R_ring_MCP_joint\",\n",
    "    \"R_ring_DIP_joint\",\n",
    "    \"R_pinky_MCP_joint\",\n",
    "    \"R_pinky_DIP_joint\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c17fb87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import scipy.spatial.transform as transform\n",
    "import numpy as np\n",
    "import os\n",
    "import transforms3d\n",
    "\n",
    "\n",
    "def euler_to_rotation_matrix(euler_angles):\n",
    "    rotation = R.from_euler('XYZ', euler_angles, degrees=False)\n",
    "    return rotation.as_matrix()\n",
    "\n",
    "\n",
    "def quaternion_to_rotation_matrix(quaternion):\n",
    "    rotation = R.from_quat(quaternion)\n",
    "    return rotation.as_matrix()\n",
    "\n",
    "\n",
    "def object_pose_to_matrix(position, quaternion):\n",
    "    \"\"\"\n",
    "    Converts object pose (position and quaternion) to a 4x4 transformation matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - position: (3,) numpy.ndarray, position [x, y, z]\n",
    "    - quaternion: (4,) numpy.ndarray, [x, y, z, w] quaternion\n",
    "    \n",
    "    Returns:\n",
    "    - transformation_matrix: (4, 4) numpy.ndarray, corresponding transformation matrix\n",
    "    \"\"\"\n",
    "    quaternion = np.concatenate([quaternion[1:4], quaternion[0:1]]) # xyzw -> wxyz\n",
    "    rotation_matrix = quaternion_to_rotation_matrix(quaternion)\n",
    "    transformation_matrix = np.eye(4)\n",
    "    transformation_matrix[:3, :3] = rotation_matrix\n",
    "    transformation_matrix[:3, 3] = position\n",
    "    return transformation_matrix\n",
    "\n",
    "\n",
    "def hand_pose_to_matrix(position, quaternion):\n",
    "    \"\"\"\n",
    "    Converts object pose (position and quaternion) to a 4x4 transformation matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - position: (3,) numpy.ndarray, position [x, y, z]\n",
    "    - quaternion: (4,) numpy.ndarray, [x, y, z, w] quaternion\n",
    "    \n",
    "    Returns:\n",
    "    - transformation_matrix: (4, 4) numpy.ndarray, corresponding transformation matrix\n",
    "    \"\"\"\n",
    "    rotation_matrix = quaternion_to_rotation_matrix(quaternion)\n",
    "    transformation_matrix = np.eye(4)\n",
    "    transformation_matrix[:3, :3] = rotation_matrix\n",
    "    transformation_matrix[:3, 3] = position\n",
    "    return transformation_matrix\n",
    "\n",
    "def get_global_pose_for_training(global_grasp_poses, oc_hand_pose, obj_idx):\n",
    "    ''' Hand pose: trans + euler '''\n",
    "    oc_hand_trans = oc_hand_pose[:3]\n",
    "    oc_hand_orient = oc_hand_pose[3:]\n",
    "\n",
    "    ''' Obj pose '''\n",
    "    obj_pos = global_grasp_poses[obj_idx]['target_pose_world'][0].p\n",
    "    obj_quat = global_grasp_poses[obj_idx]['target_pose_world'][0].q\n",
    "    object_pose = object_pose_to_matrix(obj_pos, obj_quat)\n",
    "    W_T_O = object_pose\n",
    "\n",
    "    # Build O_T_H from object-centric pose\n",
    "    R_oh = R.from_euler('xyz', oc_hand_orient, degrees=False).as_matrix()\n",
    "    O_T_H = np.eye(4)\n",
    "    O_T_H[:3, :3] = R_oh\n",
    "    O_T_H[:3, 3]  = np.asarray(oc_hand_trans)\n",
    "\n",
    "    # Back to world: W_T_H = W_T_O @ O_T_H\n",
    "    W_T_H = W_T_O @ O_T_H\n",
    "\n",
    "    # Extract\n",
    "    R_wh = W_T_H[:3, :3]\n",
    "    t_wh = W_T_H[:3, 3]\n",
    "    euler_wh = R.from_matrix(R_wh).as_euler('XYZ', degrees=False)\n",
    "    quat_wh  = R.from_matrix(R_wh).as_quat()  # (x,y,z,w)\n",
    "\n",
    "    # 6D rotation like your forward function\n",
    "    hand_6drot_world = R_wh[:, :2].T.ravel().tolist()\n",
    "\n",
    "    # Hand pose in world frame\n",
    "    hand_pose_world = t_wh.tolist() + euler_wh.tolist()\n",
    "\n",
    "    return hand_pose_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7f488a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object_idx: 25 E_pen: 0.0\n",
      "object_idx: 24 E_pen: 0.02102472260594368\n",
      "object_idx: 2 E_pen: 0.03550920635461807\n",
      "object_idx: 19 E_pen: 0.09591756761074066\n"
     ]
    }
   ],
   "source": [
    "# load global grasp pose\n",
    "global_grasp_poses_dict =np.load('/home/ubuntu/Documents/DexYCB/grasp_poses.npy', allow_pickle=True).item()\n",
    "\n",
    "# load opt results\n",
    "result_path = \"/home/ubuntu/Documents/DexGraspNet/data/experiments/exp_2/results_real_v0\"\n",
    "refine_dict = defaultdict(dict)\n",
    "e_pen_list = []\n",
    "for fname in os.listdir(result_path):\n",
    "    if fname.endswith(\".npy\"):\n",
    "        # Remove extension and split at first underscore\n",
    "        name_no_ext = os.path.splitext(fname)[0]\n",
    "        object_idx, object_code = name_no_ext.split(\"_\", 1)  # split only at first \"_\"\n",
    "        object_idx = int(object_idx)\n",
    "                \n",
    "        # object centric hand pose\n",
    "        opt_data_dict = np.load(os.path.join(result_path, name_no_ext + '.npy'), allow_pickle=True)[0]\n",
    "        hand_qpos = opt_data_dict['qpos']\n",
    "        E_pen = opt_data_dict['E_pen']\n",
    "        e_pen_list.append([E_pen, object_idx])\n",
    "        hand_trans = np.array([hand_qpos[name] for name in translation_names])\n",
    "        hand_rot = np.array([hand_qpos[name] for name in rot_names])\n",
    "        oc_hand_pose = np.concatenate([hand_trans, hand_rot])\n",
    "        # rot = hand_rot[:, :2].T.ravel().tolist()\n",
    "        # oc_hand_pose = [hand_qpos[name] for name in translation_names] + rot + [hand_qpos[name] for name in joint_names]\n",
    "\n",
    "        # load global obj pose\n",
    "        global_pose = get_global_pose_for_training(global_grasp_poses_dict, oc_hand_pose, object_idx)\n",
    "        finger_joints = [hand_qpos[name] for name in joint_names]\n",
    "\n",
    "        origin_map_idx = [0, 5, 10, 11, 1, 6, 2, 7, 3, 8, 4, 9]\n",
    "        inv_map_idx = [0] * len(origin_map_idx)\n",
    "        for new_pos, old_pos in enumerate(origin_map_idx):\n",
    "            inv_map_idx[old_pos] = new_pos\n",
    "        mapped_finger_joints = [finger_joints[i] for i in inv_map_idx]\n",
    "\n",
    "        # single pose dict for testing:\n",
    "        refine_dict[object_idx] = global_grasp_poses_dict[object_idx]\n",
    "        refine_dict[object_idx]['robot_pose'] = [np.array(global_pose + mapped_finger_joints)]\n",
    "\n",
    "e_pen_list = sorted(e_pen_list, key=lambda x: x[0])\n",
    "for e_pen in e_pen_list:\n",
    "    print(\"object_idx:\", e_pen[1], \"E_pen:\", e_pen[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a0634a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {25: {'target_object_name': '035_power_drill',\n",
       "              'target_object_idx': 15,\n",
       "              'target_pose_camera': [array([-0.888596  , -0.23289125,  0.24085154,  0.31328806,  0.26054224,\n",
       "                      -0.25049844,  0.78198594], dtype=float32)],\n",
       "              'target_pose_world': [Pose([0.489298, 0.266902, 0.346966], [-0.481551, -0.260079, -0.543124, -0.636776])],\n",
       "              'camera_pose': Pose([1.01468, 0.777723, 0.799924], [0.0533614, -0.230272, -0.91078, 0.338536]),\n",
       "              'robot_names': [<RobotName.inspire: 6>],\n",
       "              'robot_pose': [array([ 0.40081137,  0.37438832,  0.34134235,  1.75713544,  0.45729249,\n",
       "                      -0.3316439 ,  1.41893589,  0.8269974 ,  0.91402972,  0.84527212,\n",
       "                       0.85544091,  0.28981453,  0.87675709,  0.88572621,  0.77593547,\n",
       "                       0.77505094,  0.38588923,  0.2158599 ])],\n",
       "              'hand_type': <HandType.right: 1>},\n",
       "             2: {'target_object_name': '052_extra_large_clamp',\n",
       "              'target_object_idx': 20,\n",
       "              'target_pose_camera': [array([-0.00192128,  0.9743787 ,  0.17957535,  0.13540633,  0.25100455,\n",
       "                      -0.16316546,  0.7370136 ], dtype=float32)],\n",
       "              'target_pose_world': [Pose([0.54263, 0.347237, 0.325933], [0.833435, -0.524698, -0.0306306, -0.170699])],\n",
       "              'camera_pose': Pose([1.01468, 0.777723, 0.799924], [0.0533614, -0.230272, -0.91078, 0.338536]),\n",
       "              'robot_names': [<RobotName.inspire: 6>],\n",
       "              'robot_pose': [array([ 0.44843161,  0.43360766,  0.40456013,  1.85082065,  0.42568721,\n",
       "                      -1.29166992,  0.88575298,  0.77174765,  1.00965881,  1.25358534,\n",
       "                       1.3001498 ,  0.21931084,  0.74021745,  0.9755941 ,  1.24098575,\n",
       "                       1.19313121,  0.24164939,  0.11698458])],\n",
       "              'hand_type': <HandType.right: 1>},\n",
       "             19: {'target_object_name': '019_pitcher_base',\n",
       "              'target_object_idx': 11,\n",
       "              'target_pose_camera': [array([ 0.8361307 ,  0.3734782 , -0.252608  ,  0.31239212,  0.31317776,\n",
       "                      -0.16131523,  0.6692683 ], dtype=float32)],\n",
       "              'target_pose_world': [Pose([0.50526, 0.416904, 0.372928], [0.63488, 0.0763168, -0.0396996, 0.767807])],\n",
       "              'camera_pose': Pose([1.01468, 0.777723, 0.799924], [0.0533614, -0.230272, -0.91078, 0.338536]),\n",
       "              'robot_names': [<RobotName.inspire: 6>],\n",
       "              'robot_pose': [array([ 0.30816868,  0.41950557,  0.43307243,  2.23305353,  1.28333443,\n",
       "                      -0.74475339,  0.93648171,  0.76838303,  0.75630468,  0.72434908,\n",
       "                       0.65098554,  0.21589388,  0.79007131,  0.74975884,  0.73064369,\n",
       "                       0.6718176 ,  0.28311747,  0.16150331])],\n",
       "              'hand_type': <HandType.right: 1>},\n",
       "             24: {'target_object_name': '037_scissors',\n",
       "              'target_object_idx': 17,\n",
       "              'target_pose_camera': [array([ 0.91044515, -0.36565694,  0.15236866, -0.11903088,  0.38688374,\n",
       "                      -0.07650121,  0.7738215 ], dtype=float32)],\n",
       "              'target_pose_world': [Pose([0.445838, 0.444957, 0.234221], [-0.181317, 0.0610056, 0.432203, 0.881251])],\n",
       "              'camera_pose': Pose([1.01468, 0.777723, 0.799924], [0.0533614, -0.230272, -0.91078, 0.338536]),\n",
       "              'robot_names': [<RobotName.inspire: 6>],\n",
       "              'robot_pose': [array([ 0.4447894 ,  0.55382136,  0.33480953,  2.12748387, -0.27478728,\n",
       "                      -0.69488517,  1.20686972,  0.71372879,  0.78998637,  0.69437999,\n",
       "                       0.67546433,  0.34733251,  0.71308082,  0.85387009,  0.86858171,\n",
       "                       0.68630433,  0.45160151,  0.24612175])],\n",
       "              'hand_type': <HandType.right: 1>}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refine_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3f9f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store dict in a specified path as npy file\n",
    "import os\n",
    "import json\n",
    "output_path = '/home/ubuntu/Documents/DexYCB/grasp_poses_opt_real_v0.npy'\n",
    "if not os.path.exists(os.path.dirname(output_path)):\n",
    "    os.makedirs(os.path.dirname(output_path))\n",
    "np.save(output_path, refine_dict, allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dexfungrasp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
